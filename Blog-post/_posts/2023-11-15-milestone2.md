---
layout: post
title:  "IFT 6758 Project: Milestone 2"
subtitle: "Six Subtitle"
date:   2023-11-11
---


## 1. Feature Engineering I


## 2. Baseline Models

In this section, we evaluate the performance of baseline logistic regression models trained on different features of our dataset. The models were trained using only the 'distance' feature, only the 'angle' feature, and both 'distance' and 'angle' features combined.

### Baseline Model Trained on Distance

![Confusion Matrix](/assets/images/conf_matrix_distance.png)
The baseline logistic regression model using only the 'distance' feature showed an accuracy of 0.9086. However, the confusion matrix:

indicates that the model predicted no positive classes, which suggests a potential issue with class imbalance or the feature's predictive capability.

### Baseline Models Trained on Angle and Both Features

Subsequent models trained on the 'angle' feature and both 'distance' and 'angle' features did not significantly improve the predictive performance, indicating that these features alone might not be sufficient for the task at hand.

### Visualization and Interpretation

The performance of these baseline models can be visually interpreted through the following plots:

![ROC Curve Comparison](/assets/images/roc_curve_plot.png)

The ROC curve comparison illustrates that while there is some ability to distinguish between the classes, the discriminative performance of the feature of distance is greater than that of the angle feature, and has nearly the same results obtained by using both feature

![Goal Rate vs Probability Percentile Plot](/assets/images/goal_rate_plot.png)

The plot depicting the goal rate against the probability percentile conveys a consistent pattern: higher probabilities predicted by the model correlate with an increased likelihood of actual goal occurrences. This reinforces the earlier inference where the 'distance' attribute outperforms the 'angle' attribute, and has a nearly identical performance as using the combination of both features.

![Cumulative Goals Plot](/assets/images/cumulative_goal_rate_plot.png)

The graph detailing the cumulative proportion of goals underscores a recurring observation: the predictive strength of the angle feature is overshadowed by that of the distance feature. Yet again, amalgamating both features delivers a nearly identical level of discrimination.

![Calibration Curve Plot](/assets/images/calibration_curve_plot.png)

Calibration curves serve as a metric to gauge the precision of a classifier's probability estimations. A visual inspection of these curves indicates a general trend of suboptimal calibration across the models, likely attributable to data imbalance. The angle feature, when isolated, exhibits modest reliability, whereas its combination with the distance feature enhances dependability. This plot also validates the positive correlation between the distance feature and the model's scoring accuracy.

To encapsulate, the distance attribute emerges as a pivotal factor for the model's efficiency. When paired with the angle attribute, the model's efficacy is modestly amplified. In contrast, the angle attribute, on its own, exhibits a tendency to align with the random baseline rather than displaying substantial discriminative capacity.

The three models can be found under the 'models' directory within the specific Comet.ml project entry.

- **Angle Model**: The logistic regression model trained exclusively on the angle feature.
- **Distance Model**: The logistic regression model trained solely on the distance feature.
- **Combined Model**: The logistic regression model that utilizes both distance and angle features for prediction.

The models are accessible through the following Comet.ml project entry:
[Comet.ml Project: NHL Data Science](https://www.comet.com/mahmoodhegazy/nhl-data-science/916f8c382bc04495adeeef4cf15b98e9?experiment-tab=assetStorage)
### Discussion

The baseline logistic regression models provided a starting point for understanding the predictive capability of individual features. However, their performance indicates the need for more complex models or additional features to capture the nuances of the dataset effectively. Future steps would involve exploring more sophisticated models or feature engineering techniques to improve the predictive performance.



## 3. Feature Engineering II

<b> List of Added Features</b><br>

<ol>
    <li> <b>gameID_eventID :</b> Event_Game ID for identifying unique events (PK)</li>
    <li> <b>game_period :</b> current period of the game.</li>
    <li> <b>game_seconds :</b> Total number of seconds elapsed in the game</li>
    <li> <b>x_coordinate :</b> shot x coordinate</li>
    <li> <b>y_coordinate :</b> shot y coordinate</li>
    <li> <b>shot_distance_to_goal :</b> distance between x,y coordinates of the shot and the net</li>
    <li> <b>shot_angle :</b> the shot angle.</li>
    <li> <b>shot_type :</b> type of shot</li>
    <li> <b>last_event :</b>  last event type</li>
    <li> <b>last_x_coordinate :</b> last event x coordinate</li>
    <li> <b>last_y_coordinate :</b> last event y coordinate</li>
    <li> <b>distance_from_last_event :</b> distance between x,y coordinates of current event and last event</li>
    <li> <b>time_from_last_event :</b> time passed in seconds since the last event</li>
    <li> <b>rebound :</b> Indicator of whether or not this is a rebound shot. Will be True on the 2nd successive shot, otherwise False.</li>
    <li> <b>speed :</b>  the distance from the previous event divided by the time since the previous event (distance_from_last_event/time_from_last_event).</li>
    <li> <b>change_in_shot_angle :</b> Represents the difference in the angles of consecutive shots relative to the goal. Specifically, it measures the deviation between the angle formed by the last shot and the goal, and the angle formed by the current rebound shot and the goal </li>
    <li> <b>time_since_powerplay_started :</b>  indicates the number of seconds that have passed since the beginning of a power-play. This timer resets to zero once the power-play concludes. </li>
    <li> <b>num_friendly_non_goalie_skaters :</b> denotes the count of skaters from the shooter's team present on the ice, excluding the goalie</li>
    <li> <b>num_opposing_non_goalie_skaters :</b> denotes the count of skaters from the opposing team present on the ice, excluding the goalie</li>
 
</ol>

<b>Comet.ml link storing the required experiment dataframe (wpg_v_wsh_2017021065):</b><br>

<a href="https://www.comet.com/mahmoodhegazy/nhl-data-science/9d2048b8c5d8422db2a2e4ee3551d5c9"> https://www.comet.com/mahmoodhegazy/nhl-data-science/9d2048b8c5d8422db2a2e4ee3551d5c9 </a>

## 4. Advanced Models


## 5. Other/Best Shot Models

### Various Techniques Discussion
<b> (ROC/AUC curve, goal rate vs probability percentile, cumulative proportion of goals vs probability percentile, and the reliability curve)</b>

<b>Training Data</b> - Data from year 2015/16 - 2018/19.<br><br>

## 6. Evaluate on test set

## Test on 2019/20 Regular Season Dataset

Our evaluation of the five models on the untouched 2019/20 2020/21 regular season dataset yielded insightful results. While the logistic regression models showed consistent accuracy, they lacked in F1 score, recall, and precision, indicating that they may not be as effective in classifying goals within the dataset. On the other hand, the XGBoost and Cat Boost models not only showed higher accuracy but also performed significantly better across all other metrics, suggesting a more balanced classification capability.

### ROC/AUC Curves
![ROC Curves for All Models - Regular Season](/assets/images/roc_all_models.png)

### Goal Rate vs Probability Percentile
![Goal Rate vs Probability Percentile - Regular Season](/assets/images/all_models_goal_rate.png)

### Cumulative Proportion of Goals vs Probability Percentile
![Cumulative Proportion of Goals - Regular Season](/assets/images/all_models_cumulative_goals.png)

### Reliability Curve
![Combined Calibration Curves - Regular Season](/assets/images/combined_calibration_curves.png)

The models largely mirrored their validation set performance when applied to the untouched test set, maintaining satisfactory levels of accuracy and demonstrating reliable predictive capabilities. This consistency between the validation and test sets reaffirms the robustness of the modeling approach
## Test on 2019/20 Playoff Games

### ROC/AUC Curves
![ROC Curves for All Models - Playoff Games](/assets/images/roc_all_models_playoff.png)

### Goal Rate vs Probability Percentile
![Goal Rate vs Probability Percentile - Playoff Games](/assets/images/all_models_goal_rate_playoff.png)

### Cumulative Proportion of Goals vs Probability Percentile
![Cumulative Proportion of Goals - Playoff Games](/assets/images/all_models_cumulative_goals_playoff.png)

### Reliability Curve
![Combined Calibration Curves - Playoff Games](/assets/images/combined_calibration_curves_playoff.png)

### Summary Metrics

The table below summarizes the performance metrics of each model across both regular and playoff datasets.

| Model | Accuracy (Regular) | F1 Score (Regular) | Recall (Regular) | Precision (Regular) | Accuracy (Playoff) | F1 Score (Playoff) | Recall (Playoff) | Precision (Playoff) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Logistic Regression Distance | 0.9030 | 0.0000 | 0.0000 | 0.0000 | 0.9123 | 0.0000 | 0.0000 | 0.0000 |
| Logistic Regression Angle | 0.9030 | 0.0000 | 0.0000 | 0.0000 | 0.9123 | 0.0000 | 0.0000 | 0.0000 |
| Logistic Regression Both | 0.9030 | 0.0000 | 0.0000 | 0.0000 | 0.9123 | 0.0000 | 0.0000 | 0.0000 |
| XGBoost | 0.9401 | 0.5653 | 0.4014 | 0.9557 | 0.9469 | 0.5779 | 0.4145 | 0.9539 |
| Cat Boost | 0.9440 | 0.5972 | 0.4280 | 0.9873 | 0.9512 | 0.6172 | 0.4484 | 0.9898 |

During the playoff games, our models displayed robust generalization, with the XGBoost and Cat Boost models showing improved precision and recall, suggesting their effectiveness in capturing the dynamic nature of playoff hockey. Despite high accuracy, logistic regression models continued to struggle with positive class predictions, indicating a need for more complex models for goal event prediction. The enhanced performance of complex models in playoffs, as seen in ROC/AUC and calibration curves, underscores their reliability in high-stakes scenarios, emphasizing their predictive strength over simpler models