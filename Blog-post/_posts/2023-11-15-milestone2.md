---
layout: post
title:  "IFT 6758 Project: Milestone 2"
subtitle: "Six Subtitle"
date:   2023-11-11
---


## 1. Feature Engineering I


## 2. Baseline Models


## 3. Feature Engineering II

<b> List of Added Features</b><br>

<ol>
    <li> <b>gameID_eventID :</b> Event_Game ID for identifying unique events (PK)</li>
    <li> <b>game_period :</b> current period of the game.</li>
    <li> <b>game_seconds :</b> Total number of seconds elapsed in the game</li>
    <li> <b>x_coordinate :</b> shot x coordinate</li>
    <li> <b>y_coordinate :</b> shot y coordinate</li>
    <li> <b>shot_distance_to_goal :</b> distance between x,y coordinates of the shot and the net</li>
    <li> <b>shot_angle :</b> the shot angle.</li>
    <li> <b>shot_type :</b> type of shot</li>
    <li> <b>last_event :</b>  last event type</li>
    <li> <b>last_x_coordinate :</b> last event x coordinate</li>
    <li> <b>last_y_coordinate :</b> last event y coordinate</li>
    <li> <b>distance_from_last_event :</b> distance between x,y coordinates of current event and last event</li>
    <li> <b>time_from_last_event :</b> time passed in seconds since the last event</li>
    <li> <b>rebound :</b> Indicator of whether or not this is a rebound shot. Will be True on the 2nd successive shot, otherwise False.</li>
    <li> <b>speed :</b>  the distance from the previous event divided by the time since the previous event (distance_from_last_event/time_from_last_event).</li>
    <li> <b>change_in_shot_angle :</b> Represents the difference in the angles of consecutive shots relative to the goal. Specifically, it measures the deviation between the angle formed by the last shot and the goal, and the angle formed by the current rebound shot and the goal </li>
    <li> <b>time_since_powerplay_started :</b>  indicates the number of seconds that have passed since the beginning of a power-play. This timer resets to zero once the power-play concludes. </li>
    <li> <b>num_friendly_non_goalie_skaters :</b> denotes the count of skaters from the shooter's team present on the ice, excluding the goalie</li>
    <li> <b>num_opposing_non_goalie_skaters :</b> denotes the count of skaters from the opposing team present on the ice, excluding the goalie</li>
 
</ol>

<b>Comet.ml link storing the required experiment dataframe (wpg_v_wsh_2017021065):</b><br>

<a href="https://www.comet.com/mahmoodhegazy/nhl-data-science/9d2048b8c5d8422db2a2e4ee3551d5c9"> https://www.comet.com/mahmoodhegazy/nhl-data-science/9d2048b8c5d8422db2a2e4ee3551d5c9 </a>

## 4. Advanced Models


## 5. Other/Best Shot Models
<b> (ROC/AUC curve, goal rate vs probability percentile, cumulative proportion of goals vs probability percentile, and the reliability curve)</b>


### Experiments Setup (Same accross all experiments)

<b>Training Data</b> - All data for <b>regular</b> seasons 2016/17 - 2018/19.<br><br>

All Experiments have a pipeline created through the <b>create_pipeline</b> function found in other_ml_models.py. It is a versatile tool for building a complete machine learning pipeline, handling preprocessing (both numerical and categorical), optional feature selection, and model fitting in a streamlined and efficient manner. This setup is especially useful for ensuring consistency in data transformations across both training and testing datasets. The breakdown is as follows:

##### **Setting Up Encoders Choice**
- Initializes a dictionary `encoders` with `OrdinalEncoder` (default) and `OneHotEncoder`. 

##### **Creating Transformers**
- `numeric_transformer`: Processes numerical data by imputing missing values and scaling.
- `categorical_transformer`: Processes categorical data by imputing missing values and applying the chosen encoder.

##### **Column Transformer**
- `preprocessor`: A `ColumnTransformer` that applies the correct transformations to numerical and categorical columns.

##### **Building the Full Pipeline**
- Constructs a `Pipeline` object with the preprocessing steps, optional feature selection, and the classifier.

### Hyperparameter tunning Methodology
- Sci-kit learn's `GridSearchCV`  was used to perform Grid Search with 3-fold Cross-Validation across a pred-defined hyperparameter space (defined according to model). The method searchs through the specified subset of hyperparameters for a model and finds the most effective combination. The best model is then used for training and validation.

### Feature Selection Methodology
- Sci-kit learn's `RFECV` (Recursive Feature Elimination with Cross-Validation) was deployed on all algorithms to find the best features per model. It is a feature selection method that iteratively fits a model and removes the least important features based on certain criteria, using cross-validation to assess model performance at each step. This process continues until the optimal number of features is reached, ensuring that the selected features contribute most effectively to the model's predictive accuracy.

### Various Techniques Discussion

#### Random Forest 
Random Forest Classifiers are an ensemble learning method that operate by constructing a multitude of decision trees (weak learners) at training time, leading to improved accuracy and robustness to overfitting. They make predictions taking the majority vote across these diverse trees. It performed very well on the validation set with a **94.69%** accuracy. It was the 2'nd best performer among all classifiers. This was expected as Random Forests are very good at capturing non-linear relationships between features, which is often the case in complex scenarios like sports events where the outcome (goal or no goal) can depend on a multitude of interrelated factors.

##### **Experiment Link**

<a href="https://www.comet.com/mahmoodhegazy/nhl-data-science/34144ddb714e4845be497ce0e144f098">Random_Forest_Best_Shot</a><br>

##### **Pipeline**

![image](/assets/images/rf_pipe.png)

##### **Feature Selection and Importance** : 

![image](/assets/images/rf_best_features.png)

##### **ROC/AUC curve**

![image](/assets/images/rf_roc.png)

##### **Precesion-Recall curve**

![image](/assets/images/rf_prec_rec.png)

##### **Goal Rate vs probability percentile plot**

![image](/assets/images/rf_goal_rate.png)

##### **Cumulative proportion of goals vs probability percentile plot**

![image](/assets/images/rf_cumulative_goal.png)

##### **Reliability Curve**

![image](/assets/images/rf_calib.png)


#### CatBoost
With some intuition from Part 5 that Boosting algoriths might work well in this task, another high-performance open source library for gradient boosting on decision trees, CatBoost, was leveraged. CatBoost is particularly effective at processing categorical data. And since from our RF experiment we know that both `shot_type` and `last_event` (our only 2 categorical features) were in the top 4 important features, we thought to try CatBoost out. It performed the **best** amongst all models with a validation accuracy of **94.78%**.

##### **Experiment Link**

<a href="https://www.comet.com/mahmoodhegazy/nhl-data-science/5099680072f7468a9e7d2cec05526378">CatBoost_Best_Shot</a><br>

##### **Pipeline**

![image](/assets/images/cat_pipe.png)

##### **Feature Selection and Importance** : 

![image](/assets/images/cat_best_features.png)

##### **ROC/AUC curve**

![image](/assets/images/cat_roc.png)

##### **Precesion-Recall curve**

![image](/assets/images/cat_prec_rec.png)

##### **Goal Rate vs probability percentile plot**

![image](/assets/images/cat_goal_rate.png)

##### **Cumulative proportion of goals vs probability percentile plot**

![image](/assets/images/cat_cumulative_goal.png)

##### **Reliability Curve**

![image](/assets/images/cat_calib.png)



#### K-Nearest-Neighbours

K-Nearest Neighbors (KNN) is a supervised learning algorithm that classifies or predicts the group of a data point based on the proximity to its nearest neighbors in the dataset, operating without the need for predefined parameters. It performed well but was the weakest amongst the the afore-mentioned (part 6) models.

##### **Experiment Link**

<a href="https://www.comet.com/mahmoodhegazy/nhl-data-science/b80593d676374abb90be80dd5f748c5a">KNN_Best_Shot</a><br>

##### **Pipeline**

![image](/assets/images/knn_pipe.png)

##### **ROC/AUC curve**

![image](/assets/images/knn_roc.png)

##### **Precesion-Recall curve**

![image](/assets/images/knn_prec_rec.png)

##### **Goal Rate vs probability percentile plot**

![image](/assets/images/knn_goal_rate.png)

##### **Cumulative proportion of goals vs probability percentile plot**

![image](/assets/images/knn_cumulative_goal.png)

##### **Reliability Curve**

![image](/assets/images/knn_calib.png)



#### MLP (Multi-layer Perceptron classifier)
The Multilayer Perceptron (MLP) is a type of artificial neural network that operates in a feedforward manner, effectively mapping input data to corresponding outputs. It is composed of multiple layers, with each layer being fully connected to the subsequent one. It performed well but was the weakest amongst all (part 6) models.

##### **Experiment Link**

<a href="https://www.comet.com/mahmoodhegazy/nhl-data-science/713fc623dc8d4c5eb8e54a503cb0638c">MLP_Best_Shot</a><br>

##### **Pipeline**

![image](/assets/images/mlp_pipeline_arch.png)

##### **Precesion-Recall curve**

![image](/assets/images/mlp_prec_rec.png)

##### **ROC/AUC curve**

![image](/assets/images/mlp_roc.png)

##### **Goal Rate vs probability percentile plot**

![image](/assets/images/mlp_goal_rate.png)

##### **Cumulative proportion of goals vs probability percentile plot**

![image](/assets/images/mlp_cumulative_goal.png)

##### **Reliability Curve**

![image](/assets/images/mlp_calib.png)


### Conclusion

Picking the best model is not only looking at accuracy. We have a class imbalance where only ~10% of events are goals and therefore looking into other metrics such as precision and recall is crucial. 
 - Precision measures the accuracy of the positive predictions. In the context of our task, a high precision would mean that when our model predicts a goal, it's very likely to be a goal. This is important in scenarios where the credibility of the prediction is crucial.
 - Recall measures the ability of the model to find all relevant instances og goals. In the context of our task, a high recall would mean that the model is good at identifying shots that are likely to be goals. Favoring recall is ideal when we want to ensure you capture as many potential goal-scoring opportunities as possible, even if it means including more false positives.

 It is important to hit nice balance between precision and recall and the precision-recall curve with the highest AUC will be the best that strikes that balance. For our case that is **CatBoost**, which also happens to have the highest accuracy as well.





